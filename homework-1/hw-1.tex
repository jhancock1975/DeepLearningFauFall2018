\documentclass[12pt, letterpaper]{article}
\usepackage[utf8]{inputenc} %document endcoding
\title{CAP 6619 Deep Learning Homework 1}
\author{John Hancock}

% for block quote
\usepackage{etoolbox}

\begin{document}
\maketitle
\section{Introduction}
This document contains our answers to the questions in the first homework 
assignment of CAP 6619: Deep Learning, taught by Dr. Xingquan Zhu at Florida
Atlantic University in the Fall of 2018.

Dr. Zhu is the author of the questions and tasks we answer and do in this 
document. We find the original document specifying this first homework 
assignment in \cite{homework1}. 
\section{Question 1}
Homework one begins with a task and two questions
\begin{quote}
Please show the perceptron structure and explain the function of each component
[0.5 pt]. What is the purpose of using training examples in a neural network? Given property weight
values, what is expected output vs. actual output of an example? [0.5 pt] 
\cite{homework1}
\end{quote} 
\subsection{Perceptron Structure}
Dr. Zhu gives the perceptron structure in G
\begin{thebibliography}{9}
\bibitem{latexcompanion} 
Michel Goossens, Frank Mittelbach, and Alexander Samarin. 
\textit{The \LaTeX\ Companion}. 
Addison-Wesley, Reading, Massachusetts, 1993.
 
\bibitem{einstein} 
Albert Einstein. 
\textit{Zur Elektrodynamik bewegter K{\"o}rper}. (German) 
[\textit{On the electrodynamics of moving bodies}]. 
Annalen der Physik, 322(10):891â€“921, 1905.
 
\bibitem{knuthwebsite} 
Knuth: Computers and Typesetting,
\\\texttt{http://www-cs-faculty.stanford.edu/\~{}uno/abcde.html}

\bibitem{homework1}
Zhu: Homework 1
\\\texttt{https://canvas.fau.edu/files/14059715/download?download\_frd}

\bibitem{perceptronlecture}
Xingquan Zhu. 2018. Perceptron Architecture and Learning. (August 2018). 
Retrieved September 8, 2018 from \\\texttt{https://canvas.fau.edu/courses/50073/files/folder/Lectures?preview=14020569}
\end{thebibliography}

\end{document}
